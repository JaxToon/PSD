{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67064c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDb Movie Review Scraper (Selenium Version)\n",
      "-------------------------------------------\n",
      "Note: This script requires Chrome and chromedriver to be installed.\n",
      "It will automatically download chromedriver if not already installed.\n",
      "Initial setup may take a moment.\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 12:00:22,949 - INFO - \n",
      "Searching for movie: avatar\n",
      "2025-04-24 12:00:22,950 - INFO - ====== WebDriver manager ======\n",
      "2025-04-24 12:00:24,241 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-04-24 12:00:24,385 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-04-24 12:00:24,476 - INFO - Driver [C:\\Users\\LEGION\\.wdm\\drivers\\chromedriver\\win64\\135.0.7049.114\\chromedriver-win32/chromedriver.exe] found in cache\n",
      "2025-04-24 12:00:25,653 - INFO - Searching with URL: https://www.imdb.com/find/?q=avatar&s=tt&exact=true\n",
      "2025-04-24 12:00:34,836 - INFO - Found 25 results using selector: .find-result-item\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found the following movies:\n",
      "1. Avatar (2009) - tt0499549\n",
      "2. Avatar: The Last Airbender (2005) - tt0417299\n",
      "3. Tomorrow Never Dies (1997) - tt0120347\n",
      "4. Avatar (2016) - tt5863892\n",
      "5. Avatar (2022) - tt27931855\n",
      "6. Avatar (2011) - tt1775309\n",
      "7. Avatar (1916) - tt0278325\n",
      "8. Avatar (1941) - tt0154182\n",
      "9. Avatar (2003) - tt0375570\n",
      "10. Avatar (2006) - tt1622577\n",
      "11. Chrysalis (2007) - tt0884335\n",
      "12. Avatar (1964) - tt0959431\n",
      "13. Avatar (2005) - tt0497595\n",
      "14. Rifftrax: Avatar (2010) - tt16492516\n",
      "15. Cyber Wars (2004) - tt0270841\n",
      "16. Avatar (2008) - tt1378189\n",
      "17. Avatar (2021) - tt21833600\n",
      "18. Avatar (1979) - tt2136754\n",
      "19. Avatar (2004) - tt0709042\n",
      "20. Avatar (2022) - tt32623861\n",
      "21. Avatar (1996) - tt0751080\n",
      "22. Avatar (2006) - tt0860057\n",
      "23. Avatar (2007) - tt1015442\n",
      "24. Avatar (2000) - tt0703664\n",
      "25. Avatar (2009) - tt10932508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 12:00:37,670 - INFO - \n",
      "Scraping reviews for: Avatar (tt0499549)\n",
      "2025-04-24 12:00:37,671 - INFO - Waiting for review page to fully load...\n",
      "2025-04-24 12:00:44,864 - INFO - Saved debug HTML to debug_imdb_tt0499549.html\n",
      "2025-04-24 12:00:44,961 - WARNING - No reviews found with standard selectors. Trying alternative approach.\n",
      "2025-04-24 12:00:44,983 - WARNING - No reviews found on initial page. Page structure may have changed.\n",
      "2025-04-24 12:01:10,637 - INFO - No 'Load More' button found. All reviews loaded or button selector changed.\n",
      "2025-04-24 12:01:10,638 - INFO - \n",
      "Found 0 reviews for Avatar\n",
      "2025-04-24 12:01:10,640 - INFO - \n",
      "Reviews saved to reviews/reviews_tt0499549_Avatar.json\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def initialize_driver():\n",
    "    \"\"\"Initialize and return a Selenium WebDriver\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    \n",
    "    # Randomize user agent to avoid detection\n",
    "    user_agents = [\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\",\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/109.0\",\n",
    "        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "    ]\n",
    "    \n",
    "    chrome_options.add_argument(f\"--user-agent={random.choice(user_agents)}\")\n",
    "    \n",
    "    # Additional options to avoid detection\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    \n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        # Execute CDP command to bypass bot detection\n",
    "        driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "            \"source\": \"\"\"\n",
    "                Object.defineProperty(navigator, 'webdriver', {\n",
    "                    get: () => undefined\n",
    "                })\n",
    "            \"\"\"\n",
    "        })\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize driver: {e}\")\n",
    "        raise\n",
    "\n",
    "def random_delay(min_seconds=2, max_seconds=5):\n",
    "    \"\"\"Add a random delay between requests to avoid detection\"\"\"\n",
    "    delay = random.uniform(min_seconds, max_seconds)\n",
    "    time.sleep(delay)\n",
    "    return delay\n",
    "\n",
    "def search_movie_by_title(movie_title, driver):\n",
    "    \"\"\"Search for a movie by title using Selenium WebDriver\"\"\"\n",
    "    search_url = f\"https://www.imdb.com/find/?q={movie_title.replace(' ', '+')}&s=tt&exact=true\"\n",
    "    \n",
    "    logger.info(f\"Searching with URL: {search_url}\")\n",
    "    \n",
    "    try:\n",
    "        # Visit the IMDb homepage first to get cookies\n",
    "        driver.get(\"https://www.imdb.com/\")\n",
    "        random_delay(2, 4)\n",
    "        \n",
    "        # Now navigate to the search URL\n",
    "        driver.get(search_url)\n",
    "        random_delay(3, 5)\n",
    "        \n",
    "        # Wait for search results to appear - updated selectors for 2025 IMDb\n",
    "        try:\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".find-result-item\"))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            logger.warning(\"Timeout waiting for search results. Trying alternative selector.\")\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".ipc-metadata-list-summary-item\"))\n",
    "            )\n",
    "        \n",
    "        # Parse the page using BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Find movie results\n",
    "        search_results = []\n",
    "        \n",
    "        # Try multiple possible selectors for results\n",
    "        result_selectors = [\n",
    "            '.find-result-item',           # Current IMDb (2025)\n",
    "            '.ipc-metadata-list-summary-item',  # Alternative format\n",
    "            '.findResult'                  # Legacy format\n",
    "        ]\n",
    "        \n",
    "        for selector in result_selectors:\n",
    "            result_items = soup.select(selector)\n",
    "            if result_items:\n",
    "                logger.info(f\"Found {len(result_items)} results using selector: {selector}\")\n",
    "                break\n",
    "        \n",
    "        if not result_items:\n",
    "            # Try alternative search format\n",
    "            alternative_url = f\"https://www.imdb.com/search/title/?title={movie_title.replace(' ', '+')}\"\n",
    "            logger.info(f\"No results found. Trying alternative search: {alternative_url}\")\n",
    "            \n",
    "            driver.get(alternative_url)\n",
    "            random_delay(3, 5)\n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            result_items = soup.select('.lister-item')\n",
    "        \n",
    "        # Process search results\n",
    "        for item in result_items:\n",
    "            try:\n",
    "                # Find the title link - try multiple possible selectors\n",
    "                link = (\n",
    "                    item.select_one('a[href*=\"/title/tt\"]') or \n",
    "                    item.select_one('.ipc-metadata-list-summary-item__t') or\n",
    "                    item.select_one('.result_text a')\n",
    "                )\n",
    "                \n",
    "                if not link:\n",
    "                    continue\n",
    "                \n",
    "                title = link.text.strip()\n",
    "                href = link.get('href', '')\n",
    "                \n",
    "                # Extract IMDb ID\n",
    "                imdb_id_match = re.search(r'/title/(tt\\d+)/?', href)\n",
    "                if not imdb_id_match:\n",
    "                    continue\n",
    "                \n",
    "                imdb_id = imdb_id_match.group(1)\n",
    "                \n",
    "                # Try to extract year using various selectors\n",
    "                year = \"Unknown\"\n",
    "                year_element = (\n",
    "                    item.select_one('.year_type') or\n",
    "                    item.select_one('.lister-item-year') or\n",
    "                    None\n",
    "                )\n",
    "                \n",
    "                if year_element:\n",
    "                    year_match = re.search(r'(\\d{4})', year_element.text)\n",
    "                    if year_match:\n",
    "                        year = year_match.group(1)\n",
    "                else:\n",
    "                    # Try to find year in the item text\n",
    "                    year_match = re.search(r'(\\d{4})', item.text)\n",
    "                    if year_match:\n",
    "                        year = year_match.group(1)\n",
    "                \n",
    "                search_results.append({\n",
    "                    'title': title,\n",
    "                    'year': year,\n",
    "                    'imdb_id': imdb_id\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error parsing result: {e}\")\n",
    "        \n",
    "        return search_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during search: {e}\")\n",
    "        return []\n",
    "\n",
    "def scrape_reviews_page(page_source, imdb_id):\n",
    "    \"\"\"Extract reviews from the page HTML\"\"\"\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Debug: Save the HTML to examine the structure\n",
    "    with open(f\"debug_imdb_{imdb_id}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(soup.prettify())\n",
    "    \n",
    "    logger.info(f\"Saved debug HTML to debug_imdb_{imdb_id}.html\")\n",
    "    \n",
    "    # Updated selectors for 2025 IMDb review container\n",
    "    review_containers = []\n",
    "    review_selectors = [\n",
    "        'div.review-container',        # Standard format\n",
    "        '.imdb-user-review',           # Legacy format\n",
    "        '.lister-item.review-item',    # Alternative format\n",
    "        '.review-container',           # Direct container\n",
    "        '.ipl-content-list__item',     # List item container\n",
    "        'div[data-testid=\"review\"]',   # New data-testid format (common in 2025)\n",
    "        'article.review',              # Article format\n",
    "        '.review-list-item'            # List item format\n",
    "    ]\n",
    "    \n",
    "    for selector in review_selectors:\n",
    "        review_containers = soup.select(selector)\n",
    "        if review_containers:\n",
    "            logger.info(f\"Found {len(review_containers)} reviews using selector: {selector}\")\n",
    "            break\n",
    "    \n",
    "    # If no reviews found with standard selectors, try a more generic approach\n",
    "    if not review_containers:\n",
    "        logger.warning(\"No reviews found with standard selectors. Trying alternative approach.\")\n",
    "        \n",
    "        # Look for any elements containing common review text patterns\n",
    "        potential_reviews = []\n",
    "        for elem in soup.find_all(['div', 'article', 'section']):\n",
    "            text = elem.text.lower()\n",
    "            if ('rated this' in text or 'out of 10' in text or 'user review' in text) and len(text) > 100:\n",
    "                potential_reviews.append(elem)\n",
    "        \n",
    "        if potential_reviews:\n",
    "            logger.info(f\"Found {len(potential_reviews)} potential reviews using text pattern matching\")\n",
    "            review_containers = potential_reviews\n",
    "    \n",
    "    data = {}\n",
    "    data['ImdbId'] = imdb_id\n",
    "    reviews_text = []\n",
    "    \n",
    "    for review in review_containers:\n",
    "        review_imdb = {}\n",
    "        \n",
    "        # Reviewer name\n",
    "        try:\n",
    "            # Try multiple possible selectors\n",
    "            name_element = (\n",
    "                review.select_one('.display-name-link a') or\n",
    "                review.select_one('.review-container__author a') or\n",
    "                review.select_one('.review-container__name') or\n",
    "                review.select_one('.author a')\n",
    "            )\n",
    "            \n",
    "            if name_element:\n",
    "                review_imdb['reviewer_name'] = name_element.text.strip()\n",
    "            else:\n",
    "                review_imdb['reviewer_name'] = \"\"\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting reviewer name: {e}\")\n",
    "            review_imdb['reviewer_name'] = \"\"\n",
    "            \n",
    "        # Reviewer URL\n",
    "        try:\n",
    "            # Try multiple possible selectors\n",
    "            url_element = (\n",
    "                review.select_one('.display-name-link a') or\n",
    "                review.select_one('.review-container__author a') or\n",
    "                review.select_one('.author a')\n",
    "            )\n",
    "            \n",
    "            if url_element and url_element.has_attr('href'):\n",
    "                review_imdb['reviewer_url'] = url_element['href']\n",
    "            else:\n",
    "                review_imdb['reviewer_url'] = \"\"\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting reviewer URL: {e}\")\n",
    "            review_imdb['reviewer_url'] = \"\"\n",
    "            \n",
    "        # Review ID\n",
    "        try:\n",
    "            if review.has_attr('data-review-id'):\n",
    "                review_imdb['data-review-id'] = review['data-review-id']\n",
    "            elif review.has_attr('id'):\n",
    "                review_imdb['data-review-id'] = review['id']\n",
    "            else:\n",
    "                review_imdb['data-review-id'] = \"\"\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting review ID: {e}\")\n",
    "            review_imdb['data-review-id'] = \"\"\n",
    "            \n",
    "        # Short review (title)\n",
    "        try:\n",
    "            # Try multiple possible selectors\n",
    "            title_element = (\n",
    "                review.select_one('a.title') or\n",
    "                review.select_one('.review-title') or\n",
    "                review.select_one('.title') or\n",
    "                review.select_one('h3')\n",
    "            )\n",
    "            \n",
    "            if title_element:\n",
    "                review_imdb['short_review'] = title_element.text.strip()\n",
    "            else:\n",
    "                review_imdb['short_review'] = \"\"\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting short review: {e}\")\n",
    "            review_imdb['short_review'] = \"\"\n",
    "    \n",
    "        # Full review\n",
    "        try:\n",
    "            # Try multiple possible selectors\n",
    "            content_element = (\n",
    "                review.select_one('.show-more__control') or\n",
    "                review.select_one('.content') or\n",
    "                review.select_one('.text') or\n",
    "                review.select_one('.review-content') or\n",
    "                review.select_one('.review-text')\n",
    "            )\n",
    "            \n",
    "            if content_element:\n",
    "                review_imdb['full_review'] = content_element.text.strip()\n",
    "            else:\n",
    "                review_imdb['full_review'] = \"\"\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting full review: {e}\")\n",
    "            review_imdb['full_review'] = \"\"\n",
    "            \n",
    "        # Review date\n",
    "        try:\n",
    "            # Try multiple possible selectors\n",
    "            date_element = (\n",
    "                review.select_one('.review-date') or\n",
    "                review.select_one('.review-container__date') or\n",
    "                review.select_one('.date')\n",
    "            )\n",
    "            \n",
    "            if date_element:\n",
    "                review_imdb['review_date'] = date_element.text.strip()\n",
    "            else:\n",
    "                review_imdb['review_date'] = \"\"\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting review date: {e}\")\n",
    "            review_imdb['review_date'] = \"\"\n",
    "            \n",
    "        # Rating value\n",
    "        try:\n",
    "            # Try multiple possible selectors\n",
    "            rating_element = (\n",
    "                review.select_one('.rating-other-user-rating span') or\n",
    "                review.select_one('.ipl-ratings-bar span') or\n",
    "                review.select_one('.rating span') or\n",
    "                review.select_one('.rating')\n",
    "            )\n",
    "            \n",
    "            if rating_element:\n",
    "                rating_text = rating_element.text.strip()\n",
    "                # Extract just the number if there's a pattern like \"8/10\"\n",
    "                rating_match = re.search(r'(\\d+)(?:/\\d+)?', rating_text)\n",
    "                if rating_match:\n",
    "                    review_imdb['rating_value'] = rating_match.group(1)\n",
    "                else:\n",
    "                    review_imdb['rating_value'] = rating_text\n",
    "            else:\n",
    "                review_imdb['rating_value'] = \"\"\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting rating: {e}\")\n",
    "            review_imdb['rating_value'] = \"\"\n",
    "            \n",
    "        reviews_text.append(review_imdb)\n",
    "    \n",
    "    data['reviews'] = reviews_text\n",
    "    return data\n",
    "\n",
    "def scrape_all_reviews(imdb_id, driver, max_pages=None):\n",
    "    \"\"\"Scrape all review pages for a movie using Selenium\"\"\"\n",
    "    all_data = []\n",
    "    reviews_url = f\"https://www.imdb.com/title/{imdb_id}/reviews\"\n",
    "    \n",
    "    logger.info(f\"Opening reviews page: {reviews_url}\")\n",
    "    driver.get(reviews_url)\n",
    "    random_delay(3, 5)\n",
    "    \n",
    "    # Accept cookies if the dialog appears\n",
    "    try:\n",
    "        cookie_selectors = [\n",
    "            \"button[id*='accept']\",\n",
    "            \"button[data-testid='accept']\",\n",
    "            \".ipc-button--accept-cookies\",\n",
    "            \".accept-cookies\"\n",
    "        ]\n",
    "        \n",
    "        for selector in cookie_selectors:\n",
    "            try:\n",
    "                accept_button = WebDriverWait(driver, 3).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
    "                )\n",
    "                accept_button.click()\n",
    "                logger.info(f\"Accepted cookies using selector: {selector}\")\n",
    "                random_delay(1, 2)\n",
    "                break\n",
    "            except TimeoutException:\n",
    "                continue\n",
    "    except Exception:\n",
    "        logger.info(\"No cookie prompt found or already accepted\")\n",
    "\n",
    "    logger.info(\"Waiting for review page to fully load...\")\n",
    "    try:\n",
    "        # First wait for the page structure to load\n",
    "        WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"body\"))\n",
    "        )\n",
    "        \n",
    "        # Then wait for potential review elements\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \".ipc-list-card, article, .review-container\"))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            logger.info(\"No review elements found with standard selectors, continuing anyway\")\n",
    "        \n",
    "        # Scroll down several times to trigger lazy loading\n",
    "        for _ in range(3):\n",
    "            driver.execute_script(\"window.scrollBy(0, 800);\")\n",
    "            time.sleep(2)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Error waiting for page load: {e}\")\n",
    "    \n",
    "    page_count = 0\n",
    "    has_more = True\n",
    "    \n",
    "    # First parse the initial page\n",
    "    data = scrape_reviews_page(driver.page_source, imdb_id)\n",
    "    if data['reviews']:\n",
    "        all_data.append(data)\n",
    "        logger.info(f\"Found {len(data['reviews'])} reviews on initial page\")\n",
    "    else:\n",
    "        logger.warning(\"No reviews found on initial page. Page structure may have changed.\")\n",
    "        \n",
    "        # Try navigating to an alternative review URL\n",
    "        alt_reviews_url = f\"https://www.imdb.com/title/{imdb_id}/reviews/_ajax\"\n",
    "        logger.info(f\"Trying alternative reviews URL: {alt_reviews_url}\")\n",
    "        driver.get(alt_reviews_url)\n",
    "        random_delay(3, 5)\n",
    "        \n",
    "        # Try again with the alternative URL\n",
    "        data = scrape_reviews_page(driver.page_source, imdb_id)\n",
    "        if data['reviews']:\n",
    "            all_data.append(data)\n",
    "            logger.info(f\"Found {len(data['reviews'])} reviews on alternative page\")\n",
    "    \n",
    "    # List of possible load more button selectors\n",
    "    load_more_selectors = [\n",
    "        \".load-more-data\",\n",
    "        \"#load-more-trigger\",\n",
    "        \"button.ipc-see-more__button\",  # New \"Load More\" pattern\n",
    "        \".ipc-pagination__next-button\",  # Pagination next button\n",
    "        \"button.more-reviews\",\n",
    "        \".see-more a\",\n",
    "        \".ipl-load-more__button\",\n",
    "        \"button[data-testid='load-more']\"  # Data testid pattern\n",
    "    ]\n",
    "    \n",
    "    # Click \"Load More\" button until no more results or reached max pages\n",
    "    while has_more and (max_pages is None or page_count < max_pages):\n",
    "        try:\n",
    "            # Try each possible selector for load more button\n",
    "            load_more = None\n",
    "            used_selector = None\n",
    "            \n",
    "            for selector in load_more_selectors:\n",
    "                try:\n",
    "                    load_more = WebDriverWait(driver, 5).until(\n",
    "                        EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
    "                    )\n",
    "                    used_selector = selector\n",
    "                    break\n",
    "                except TimeoutException:\n",
    "                    continue\n",
    "            \n",
    "            if not load_more:\n",
    "                logger.info(\"No 'Load More' button found. All reviews loaded or button selector changed.\")\n",
    "                break\n",
    "            \n",
    "            logger.info(f\"Found 'Load More' button using selector: {used_selector}\")\n",
    "            \n",
    "            # Scroll to the button\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", load_more)\n",
    "            random_delay(1, 2)\n",
    "            \n",
    "            # Try to click the button\n",
    "            try:\n",
    "                load_more.click()\n",
    "                logger.info(\"Clicked 'Load More' button\")\n",
    "            except ElementClickInterceptedException:\n",
    "                # If normal click fails, try JavaScript click\n",
    "                driver.execute_script(\"arguments[0].click();\", load_more)\n",
    "                logger.info(\"Used JavaScript to click 'Load More' button\")\n",
    "            \n",
    "            # Wait for new content to load with random delay\n",
    "            random_delay(3, 6)\n",
    "            \n",
    "            # Scroll a bit after loading to ensure new content is rendered\n",
    "            driver.execute_script(\"window.scrollBy(0, 300);\")\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Check if new reviews were loaded\n",
    "            new_data = scrape_reviews_page(driver.page_source, imdb_id)\n",
    "            if new_data['reviews']:\n",
    "                current_review_count = sum(len(page['reviews']) for page in all_data)\n",
    "                new_review_count = len(new_data['reviews'])\n",
    "                \n",
    "                # Only append if we got new reviews\n",
    "                if new_review_count > current_review_count:\n",
    "                    all_data.append(new_data)\n",
    "                    page_count += 1\n",
    "                    logger.info(f\"Loaded page {page_count + 1}: Found {new_review_count} reviews (Total now: {current_review_count + new_review_count})\")\n",
    "                else:\n",
    "                    logger.info(\"No new reviews loaded, reached end of reviews\")\n",
    "                    has_more = False\n",
    "            else:\n",
    "                logger.info(\"No new reviews found after clicking load more\")\n",
    "                has_more = False\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading more reviews: {e}\")\n",
    "            has_more = False\n",
    "    \n",
    "    # Combine all reviews into a single structure\n",
    "    all_reviews = []\n",
    "    for page_data in all_data:\n",
    "        all_reviews.extend(page_data['reviews'])\n",
    "    \n",
    "    # Remove potential duplicates (based on review text)\n",
    "    unique_reviews = []\n",
    "    seen_reviews = set()\n",
    "    \n",
    "    for review in all_reviews:\n",
    "        # Create a simple hash of the review content to identify duplicates\n",
    "        review_hash = hash(review.get('full_review', '') + review.get('reviewer_name', ''))\n",
    "        if review_hash not in seen_reviews:\n",
    "            seen_reviews.add(review_hash)\n",
    "            unique_reviews.append(review)\n",
    "    \n",
    "    reviews = {\n",
    "        'ImdbId': imdb_id,\n",
    "        'total_reviews': len(unique_reviews),\n",
    "        'reviews': unique_reviews\n",
    "    }\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "def get_movie_reviews_by_title(movie_title, max_pages=None):\n",
    "    \"\"\"Main function to get reviews by movie title using Selenium\"\"\"\n",
    "    logger.info(f\"\\nSearching for movie: {movie_title}\")\n",
    "    \n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        # Search for the movie\n",
    "        search_results = search_movie_by_title(movie_title, driver)\n",
    "        \n",
    "        if not search_results:\n",
    "            logger.warning(\"No movies found matching that title.\")\n",
    "            return None\n",
    "        \n",
    "        # Display search results\n",
    "        print(\"\\nFound the following movies:\")\n",
    "        for i, movie in enumerate(search_results, 1):\n",
    "            print(f\"{i}. {movie['title']} ({movie['year']}) - {movie['imdb_id']}\")\n",
    "        \n",
    "        # Let user choose a movie or use first result in automated mode\n",
    "        selected_movie = None\n",
    "        if len(search_results) == 1:\n",
    "            selected_movie = search_results[0]\n",
    "            print(f\"Auto-selecting the only result: {selected_movie['title']}\")\n",
    "        else:\n",
    "            try:\n",
    "                choice = int(input(f\"\\nSelect a movie (1-{len(search_results)}): \"))\n",
    "                if 1 <= choice <= len(search_results):\n",
    "                    selected_movie = search_results[choice-1]\n",
    "                else:\n",
    "                    logger.error(\"Invalid selection\")\n",
    "                    return None\n",
    "            except ValueError:\n",
    "                logger.error(\"Please enter a valid number\")\n",
    "                return None\n",
    "        \n",
    "        imdb_id = selected_movie['imdb_id']\n",
    "        movie_title = selected_movie['title']\n",
    "        \n",
    "        logger.info(f\"\\nScraping reviews for: {movie_title} ({imdb_id})\")\n",
    "        \n",
    "        # Scrape reviews for the selected movie\n",
    "        data = scrape_all_reviews(imdb_id, driver, max_pages)\n",
    "        \n",
    "        # Count total reviews\n",
    "        total_reviews = len(data['reviews'])\n",
    "        \n",
    "        logger.info(f\"\\nFound {total_reviews} reviews for {movie_title}\")\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(\"reviews\", exist_ok=True)\n",
    "        \n",
    "        # Save to JSON file\n",
    "        sanitized_title = re.sub(r'[\\\\/*?:\"<>|]', \"\", movie_title.replace(' ', '_'))\n",
    "        filename = f\"reviews/reviews_{imdb_id}_{sanitized_title}.json\"\n",
    "        with open(filename, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(data, json_file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        logger.info(f\"\\nReviews saved to {filename}\")\n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        # Always close the driver when done\n",
    "        driver.quit()\n",
    "\n",
    "def main():\n",
    "    print(\"IMDb Movie Review Scraper (Selenium Version)\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"Note: This script requires Chrome and chromedriver to be installed.\")\n",
    "    print(\"It will automatically download chromedriver if not already installed.\")\n",
    "    print(\"Initial setup may take a moment.\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    \n",
    "    while True:\n",
    "        movie_title = input(\"\\nEnter movie title (or 'quit' to exit): \")\n",
    "        if movie_title.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        max_pages = None\n",
    "        page_limit = input(\"Enter maximum number of pages to scrape (or press Enter for all): \")\n",
    "        if page_limit.strip():\n",
    "            try:\n",
    "                max_pages = int(page_limit)\n",
    "            except ValueError:\n",
    "                print(\"Invalid number, scraping all pages.\")\n",
    "        \n",
    "        get_movie_reviews_by_title(movie_title, max_pages)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
